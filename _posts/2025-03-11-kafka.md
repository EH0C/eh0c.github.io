---
layout: post
title: Apache Kafka Data Streaming
subtitle: Real time data streaming using apache kafka!
tags: [test]
comments: true
mathjax: true
author: Edoardo Herianto
---

{: .box-success}
Here’s how I created a Real Time Data Streaming Application using Apache Kafka, Debezium, and Pyspark all in a dockerized environment.

![Crepe](/assets/img/kafka.png)

{: .box-note}
**Objective:** The goal is to capture real-time changes from a MariaDB database, stream them through Kafka topics, and process the data using PySpark for transformation, analysis, or further storage.

## Things I prepared beforehand:
- Installed Docker on my computer
- Download kafka-avro-serializer.jar
- Included the MySQL JDBC driver for database connectivity

## Docker Configuration:

My directory is structured like this:
~~~
my_project/
│-- docker-compose.yml
│-- pyspark/
│   ├── notebooks/  (Place your Jupyter notebooks here)
│   ├── requirements.txt  (Python dependencies)
│-- jars/  (Place your Avro/Protobuf JARs here)
~~~

My "compose.yaml" includes services for PySpark, Jupyter Notebook, Kafka, and Zookeeper
~~~
services:   

  mariadb:
    image: mariadb:10.3
    container_name: mariadb
    restart: always
    ports:
      - '3306:3306'
    environment:
      - MYSQL_ROOT_PASSWORD=passcword
      - MYSQL_USER=root
      - MYSQL_PASSWORD=password
    command: --log-bin=mysql-bin --binlog-format=ROW --server-id=1 --expire_logs_days=10
    volumes:
      - './mysql/dbdata:/var/lib/mysql'
      - './mysql/conf/my.cnf:/etc/mysql/conf.d/my.cnf'
      - './mysql/log:/var/log/mysql'

  zookeeper:
    image: wurstmeister/zookeeper:latest
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:5.5.1
    restart: always
    depends_on:
      - zookeeper
    environment:
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT"
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092"
      KAFKA_LISTENER_NAME: PLAINTEXT
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9991
    ports:
      - "9092:9092"
    volumes:
      - D:/datastreamingcomp/kafka-avro-serializer-7.6.0.wso2v1.jar:/usr/share/java/kafka-avro-console-consumer.jar

  schema-registry:
    image: confluentinc/cp-schema-registry:5.5.3
    restart: always
    environment:
      - SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL=zookeeper:2181
      - SCHEMA_REGISTRY_HOST_NAME=schema-registry
      - SCHEMA_REGISTRY_LISTENERS=http://schema-registry:8087,http://localhost:8087
    ports:
      - 8087:8087
    depends_on: [zookeeper, kafka]

  debezium:
    image: debezium/connect:1.4
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      OFFSET_STORAGE_TOPIC: connect_offsets
      STATUS_STORAGE_TOPIC: connect_status
      KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8087
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8087
      OFFSET_FLUSH_INTERVAL_MS: 60000
      OFFSET_FLUSH_TIMEOUT_MS: 5000
      SHUTDOWN_TIMEOUT: 10000
    ports:
      - 8083:8083
    depends_on:
      - kafka
      - schema-registry
    volumes:
      - D:\datastreamingcomp\kafka\config:/kafka/config
      - D:/datastreamingcomp/mysql-connector:/usr/share/java/kafka-connect

  pyspark:
    image: jupyter/pyspark-notebook:latest
    ports:
      - "8888:8888"
    environment:
      - PYSPARK_SUBMIT_ARGS=--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.0,org.apache.spark:spark-avro_2.12:3.5.0 --jars /home/jovyan/work/mysql-connector-j-9.0.0.jar pyspark-shell
    volumes:
      - D:/mariakafka/pyspark:/home/jovyan/work
      - D:/mysql-connector-j-9.0.0.jar:/home/jovyan/work/mysql-connector-j-9.0.0.jar
    depends_on:
      - kafka

networks:
  default:
    driver: bridge
~~~

Start Docker Compose:
~~~
docker-compose up -d
~~~

## Creating a Database and Sample Data in the mariadb Container:

{: .box-warning}
**Warning:** Make sure to set binlog-format=ROW.

Here's what my table looks like:

| Number | Next number | Previous number |
| :------ |:--- | :--- |
| Five | Six | Four |
| Ten | Eleven | Nine |
| Seven | Eight | Six |
| Two | Three | One |

## Create a Debezium Connection:
I Created a Debezium Connection
~~~
curl.exe -X POST -H "Content-Type: application/json" --data @D:\curls\mariadb.json http://localhost:8083/connectors
~~~
List all Connections to make sure the Debezium connection has been made
~~~
curl.exe -X GET http://localhost:8083/connectors
~~~
Check Connection Status
~~~
curl.exe -X GET http://localhost:8083/connectors/mariadb-connector/status
~~~
Check Connection Structure
~~~
curl.exe -X GET http://localhost:8087/subjects/mariadb.basecamp.employees-value/versions/latest
~~~

## Check if a topic is created in Kafka:





[This is a link to a different site](https://deanattali.com/) and [this is a link to a section inside this page](#local-urls).

Here's a table:

| Number | Next number | Previous number |
| :------ |:--- | :--- |
| Five | Six | Four |
| Ten | Eleven | Nine |
| Seven | Eight | Six |
| Two | Three | One |

You can use [MathJax](https://www.mathjax.org/) to write LaTeX expressions. For example:
When \\(a \ne 0\\), there are two solutions to \\(ax^2 + bx + c = 0\\) and they are $$x = {-b \pm \sqrt{b^2-4ac} \over 2a}.$$

How about a yummy crepe?

![Crepe](https://beautifuljekyll.com/assets/img/crepe.jpg)

It can also be centered!

![Crepe](https://beautifuljekyll.com/assets/img/crepe.jpg){: .mx-auto.d-block :}

Here's a code chunk:

~~~
var foo = function(x) {
  return(x + 5);
}
foo(3)
~~~

And here is the same code with syntax highlighting:

```javascript
var foo = function(x) {
  return(x + 5);
}
foo(3)
```

And here is the same code yet again but with line numbers:

{% highlight javascript linenos %}
var foo = function(x) {
  return(x + 5);
}
foo(3)
{% endhighlight %}

## Boxes
You can add notification, warning and error boxes like this:

### Notification

{: .box-note}
**Note:** This is a notification box.

### Warning

{: .box-warning}
**Warning:** This is a warning box.

### Error

{: .box-error}
**Error:** This is an error box.

## Local URLs in project sites {#local-urls}

When hosting a *project site* on GitHub Pages (for example, `https://USERNAME.github.io/MyProject`), URLs that begin with `/` and refer to local files may not work correctly due to how the root URL (`/`) is interpreted by GitHub Pages. You can read more about it [in the FAQ](https://beautifuljekyll.com/faq/#links-in-project-page). To demonstrate the issue, the following local image will be broken **if your site is a project site:**

![Crepe](/assets/img/crepe.jpg)

If the above image is broken, then you'll need to follow the instructions [in the FAQ](https://beautifuljekyll.com/faq/#links-in-project-page). Here is proof that it can be fixed:

![Crepe]({{ '/assets/img/crepe.jpg' | relative_url }})

<details markdown="1">
<summary>Click here!</summary>
Here you can see an **expandable** section
</details>
